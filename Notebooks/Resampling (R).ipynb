{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b4fa2bec",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Ch5-resample-lab\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f91564",
   "metadata": {},
   "source": [
    "\n",
    "# Lab: Cross-Validation and the Bootstrap\n",
    "\n",
    "In this lab, we explore the resampling techniques covered in this chapter. Some of the commands in this lab may take a while to run on your computer.\n",
    "\n",
    "## The Validation Set Approach\n",
    "\n",
    "We explore the use of the validation set approach in order to estimate the test error rates that result from fitting various linear models on the `Auto` data set.\n",
    "\n",
    "Before we begin, we use the `set.seed()` function in order to set a  for `R`'s random number generator, so that the reader of this book will\n",
    "obtain precisely the same results as those shown below. It is generally\n",
    "a good idea to set a random seed when performing an analysis such as cross-validation that contains an\n",
    "element of randomness, so that the results obtained can be reproduced precisely at a later time.\n",
    "\n",
    "We begin by using the\n",
    "`sample()` function to split the set of observations into two halves, by selecting a random subset of $196$ observations out of the original $392$ observations. We  refer\n",
    "to these observations as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb07b78",
   "metadata": {
    "name": "chunk1"
   },
   "outputs": [],
   "source": [
    "library(ISLR2)\n",
    "set.seed(1)\n",
    "train <- sample(392, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "452d528c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>324</li><li>167</li><li>129</li><li>299</li><li>270</li><li>187</li><li>307</li><li>85</li><li>277</li><li>362</li><li>330</li><li>263</li><li>329</li><li>79</li><li>213</li><li>37</li><li>105</li><li>217</li><li>366</li><li>165</li><li>290</li><li>383</li><li>89</li><li>289</li><li>340</li><li>326</li><li>382</li><li>42</li><li>111</li><li>20</li><li>44</li><li>343</li><li>70</li><li>121</li><li>40</li><li>172</li><li>25</li><li>248</li><li>198</li><li>39</li><li>298</li><li>280</li><li>160</li><li>14</li><li>130</li><li>45</li><li>22</li><li>206</li><li>230</li><li>193</li><li>104</li><li>367</li><li>255</li><li>341</li><li>342</li><li>103</li><li>331</li><li>13</li><li>296</li><li>375</li><li>176</li><li>279</li><li>110</li><li>84</li><li>29</li><li>141</li><li>252</li><li>221</li><li>108</li><li>304</li><li>33</li><li>347</li><li>149</li><li>287</li><li>102</li><li>145</li><li>118</li><li>323</li><li>107</li><li>64</li><li>224</li><li>337</li><li>51</li><li>325</li><li>372</li><li>138</li><li>390</li><li>389</li><li>282</li><li>143</li><li>285</li><li>170</li><li>48</li><li>204</li><li>295</li><li>24</li><li>181</li><li>214</li><li>225</li><li>163</li><li>43</li><li>1</li><li>328</li><li>78</li><li>284</li><li>116</li><li>233</li><li>61</li><li>86</li><li>374</li><li>49</li><li>242</li><li>246</li><li>247</li><li>239</li><li>219</li><li>135</li><li>364</li><li>363</li><li>310</li><li>53</li><li>348</li><li>65</li><li>376</li><li>124</li><li>77</li><li>218</li><li>98</li><li>194</li><li>19</li><li>31</li><li>174</li><li>237</li><li>75</li><li>16</li><li>358</li><li>9</li><li>50</li><li>92</li><li>122</li><li>152</li><li>386</li><li>207</li><li>244</li><li>229</li><li>350</li><li>355</li><li>391</li><li>223</li><li>373</li><li>309</li><li>140</li><li>126</li><li>349</li><li>344</li><li>319</li><li>258</li><li>15</li><li>271</li><li>388</li><li>195</li><li>201</li><li>318</li><li>17</li><li>212</li><li>127</li><li>133</li><li>41</li><li>384</li><li>392</li><li>159</li><li>117</li><li>72</li><li>36</li><li>315</li><li>294</li><li>157</li><li>378</li><li>313</li><li>306</li><li>272</li><li>106</li><li>185</li><li>88</li><li>281</li><li>228</li><li>238</li><li>368</li><li>80</li><li>30</li><li>93</li><li>234</li><li>220</li><li>240</li><li>369</li><li>164</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 324\n",
       "\\item 167\n",
       "\\item 129\n",
       "\\item 299\n",
       "\\item 270\n",
       "\\item 187\n",
       "\\item 307\n",
       "\\item 85\n",
       "\\item 277\n",
       "\\item 362\n",
       "\\item 330\n",
       "\\item 263\n",
       "\\item 329\n",
       "\\item 79\n",
       "\\item 213\n",
       "\\item 37\n",
       "\\item 105\n",
       "\\item 217\n",
       "\\item 366\n",
       "\\item 165\n",
       "\\item 290\n",
       "\\item 383\n",
       "\\item 89\n",
       "\\item 289\n",
       "\\item 340\n",
       "\\item 326\n",
       "\\item 382\n",
       "\\item 42\n",
       "\\item 111\n",
       "\\item 20\n",
       "\\item 44\n",
       "\\item 343\n",
       "\\item 70\n",
       "\\item 121\n",
       "\\item 40\n",
       "\\item 172\n",
       "\\item 25\n",
       "\\item 248\n",
       "\\item 198\n",
       "\\item 39\n",
       "\\item 298\n",
       "\\item 280\n",
       "\\item 160\n",
       "\\item 14\n",
       "\\item 130\n",
       "\\item 45\n",
       "\\item 22\n",
       "\\item 206\n",
       "\\item 230\n",
       "\\item 193\n",
       "\\item 104\n",
       "\\item 367\n",
       "\\item 255\n",
       "\\item 341\n",
       "\\item 342\n",
       "\\item 103\n",
       "\\item 331\n",
       "\\item 13\n",
       "\\item 296\n",
       "\\item 375\n",
       "\\item 176\n",
       "\\item 279\n",
       "\\item 110\n",
       "\\item 84\n",
       "\\item 29\n",
       "\\item 141\n",
       "\\item 252\n",
       "\\item 221\n",
       "\\item 108\n",
       "\\item 304\n",
       "\\item 33\n",
       "\\item 347\n",
       "\\item 149\n",
       "\\item 287\n",
       "\\item 102\n",
       "\\item 145\n",
       "\\item 118\n",
       "\\item 323\n",
       "\\item 107\n",
       "\\item 64\n",
       "\\item 224\n",
       "\\item 337\n",
       "\\item 51\n",
       "\\item 325\n",
       "\\item 372\n",
       "\\item 138\n",
       "\\item 390\n",
       "\\item 389\n",
       "\\item 282\n",
       "\\item 143\n",
       "\\item 285\n",
       "\\item 170\n",
       "\\item 48\n",
       "\\item 204\n",
       "\\item 295\n",
       "\\item 24\n",
       "\\item 181\n",
       "\\item 214\n",
       "\\item 225\n",
       "\\item 163\n",
       "\\item 43\n",
       "\\item 1\n",
       "\\item 328\n",
       "\\item 78\n",
       "\\item 284\n",
       "\\item 116\n",
       "\\item 233\n",
       "\\item 61\n",
       "\\item 86\n",
       "\\item 374\n",
       "\\item 49\n",
       "\\item 242\n",
       "\\item 246\n",
       "\\item 247\n",
       "\\item 239\n",
       "\\item 219\n",
       "\\item 135\n",
       "\\item 364\n",
       "\\item 363\n",
       "\\item 310\n",
       "\\item 53\n",
       "\\item 348\n",
       "\\item 65\n",
       "\\item 376\n",
       "\\item 124\n",
       "\\item 77\n",
       "\\item 218\n",
       "\\item 98\n",
       "\\item 194\n",
       "\\item 19\n",
       "\\item 31\n",
       "\\item 174\n",
       "\\item 237\n",
       "\\item 75\n",
       "\\item 16\n",
       "\\item 358\n",
       "\\item 9\n",
       "\\item 50\n",
       "\\item 92\n",
       "\\item 122\n",
       "\\item 152\n",
       "\\item 386\n",
       "\\item 207\n",
       "\\item 244\n",
       "\\item 229\n",
       "\\item 350\n",
       "\\item 355\n",
       "\\item 391\n",
       "\\item 223\n",
       "\\item 373\n",
       "\\item 309\n",
       "\\item 140\n",
       "\\item 126\n",
       "\\item 349\n",
       "\\item 344\n",
       "\\item 319\n",
       "\\item 258\n",
       "\\item 15\n",
       "\\item 271\n",
       "\\item 388\n",
       "\\item 195\n",
       "\\item 201\n",
       "\\item 318\n",
       "\\item 17\n",
       "\\item 212\n",
       "\\item 127\n",
       "\\item 133\n",
       "\\item 41\n",
       "\\item 384\n",
       "\\item 392\n",
       "\\item 159\n",
       "\\item 117\n",
       "\\item 72\n",
       "\\item 36\n",
       "\\item 315\n",
       "\\item 294\n",
       "\\item 157\n",
       "\\item 378\n",
       "\\item 313\n",
       "\\item 306\n",
       "\\item 272\n",
       "\\item 106\n",
       "\\item 185\n",
       "\\item 88\n",
       "\\item 281\n",
       "\\item 228\n",
       "\\item 238\n",
       "\\item 368\n",
       "\\item 80\n",
       "\\item 30\n",
       "\\item 93\n",
       "\\item 234\n",
       "\\item 220\n",
       "\\item 240\n",
       "\\item 369\n",
       "\\item 164\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 324\n",
       "2. 167\n",
       "3. 129\n",
       "4. 299\n",
       "5. 270\n",
       "6. 187\n",
       "7. 307\n",
       "8. 85\n",
       "9. 277\n",
       "10. 362\n",
       "11. 330\n",
       "12. 263\n",
       "13. 329\n",
       "14. 79\n",
       "15. 213\n",
       "16. 37\n",
       "17. 105\n",
       "18. 217\n",
       "19. 366\n",
       "20. 165\n",
       "21. 290\n",
       "22. 383\n",
       "23. 89\n",
       "24. 289\n",
       "25. 340\n",
       "26. 326\n",
       "27. 382\n",
       "28. 42\n",
       "29. 111\n",
       "30. 20\n",
       "31. 44\n",
       "32. 343\n",
       "33. 70\n",
       "34. 121\n",
       "35. 40\n",
       "36. 172\n",
       "37. 25\n",
       "38. 248\n",
       "39. 198\n",
       "40. 39\n",
       "41. 298\n",
       "42. 280\n",
       "43. 160\n",
       "44. 14\n",
       "45. 130\n",
       "46. 45\n",
       "47. 22\n",
       "48. 206\n",
       "49. 230\n",
       "50. 193\n",
       "51. 104\n",
       "52. 367\n",
       "53. 255\n",
       "54. 341\n",
       "55. 342\n",
       "56. 103\n",
       "57. 331\n",
       "58. 13\n",
       "59. 296\n",
       "60. 375\n",
       "61. 176\n",
       "62. 279\n",
       "63. 110\n",
       "64. 84\n",
       "65. 29\n",
       "66. 141\n",
       "67. 252\n",
       "68. 221\n",
       "69. 108\n",
       "70. 304\n",
       "71. 33\n",
       "72. 347\n",
       "73. 149\n",
       "74. 287\n",
       "75. 102\n",
       "76. 145\n",
       "77. 118\n",
       "78. 323\n",
       "79. 107\n",
       "80. 64\n",
       "81. 224\n",
       "82. 337\n",
       "83. 51\n",
       "84. 325\n",
       "85. 372\n",
       "86. 138\n",
       "87. 390\n",
       "88. 389\n",
       "89. 282\n",
       "90. 143\n",
       "91. 285\n",
       "92. 170\n",
       "93. 48\n",
       "94. 204\n",
       "95. 295\n",
       "96. 24\n",
       "97. 181\n",
       "98. 214\n",
       "99. 225\n",
       "100. 163\n",
       "101. 43\n",
       "102. 1\n",
       "103. 328\n",
       "104. 78\n",
       "105. 284\n",
       "106. 116\n",
       "107. 233\n",
       "108. 61\n",
       "109. 86\n",
       "110. 374\n",
       "111. 49\n",
       "112. 242\n",
       "113. 246\n",
       "114. 247\n",
       "115. 239\n",
       "116. 219\n",
       "117. 135\n",
       "118. 364\n",
       "119. 363\n",
       "120. 310\n",
       "121. 53\n",
       "122. 348\n",
       "123. 65\n",
       "124. 376\n",
       "125. 124\n",
       "126. 77\n",
       "127. 218\n",
       "128. 98\n",
       "129. 194\n",
       "130. 19\n",
       "131. 31\n",
       "132. 174\n",
       "133. 237\n",
       "134. 75\n",
       "135. 16\n",
       "136. 358\n",
       "137. 9\n",
       "138. 50\n",
       "139. 92\n",
       "140. 122\n",
       "141. 152\n",
       "142. 386\n",
       "143. 207\n",
       "144. 244\n",
       "145. 229\n",
       "146. 350\n",
       "147. 355\n",
       "148. 391\n",
       "149. 223\n",
       "150. 373\n",
       "151. 309\n",
       "152. 140\n",
       "153. 126\n",
       "154. 349\n",
       "155. 344\n",
       "156. 319\n",
       "157. 258\n",
       "158. 15\n",
       "159. 271\n",
       "160. 388\n",
       "161. 195\n",
       "162. 201\n",
       "163. 318\n",
       "164. 17\n",
       "165. 212\n",
       "166. 127\n",
       "167. 133\n",
       "168. 41\n",
       "169. 384\n",
       "170. 392\n",
       "171. 159\n",
       "172. 117\n",
       "173. 72\n",
       "174. 36\n",
       "175. 315\n",
       "176. 294\n",
       "177. 157\n",
       "178. 378\n",
       "179. 313\n",
       "180. 306\n",
       "181. 272\n",
       "182. 106\n",
       "183. 185\n",
       "184. 88\n",
       "185. 281\n",
       "186. 228\n",
       "187. 238\n",
       "188. 368\n",
       "189. 80\n",
       "190. 30\n",
       "191. 93\n",
       "192. 234\n",
       "193. 220\n",
       "194. 240\n",
       "195. 369\n",
       "196. 164\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 324 167 129 299 270 187 307  85 277 362 330 263 329  79 213  37 105 217\n",
       " [19] 366 165 290 383  89 289 340 326 382  42 111  20  44 343  70 121  40 172\n",
       " [37]  25 248 198  39 298 280 160  14 130  45  22 206 230 193 104 367 255 341\n",
       " [55] 342 103 331  13 296 375 176 279 110  84  29 141 252 221 108 304  33 347\n",
       " [73] 149 287 102 145 118 323 107  64 224 337  51 325 372 138 390 389 282 143\n",
       " [91] 285 170  48 204 295  24 181 214 225 163  43   1 328  78 284 116 233  61\n",
       "[109]  86 374  49 242 246 247 239 219 135 364 363 310  53 348  65 376 124  77\n",
       "[127] 218  98 194  19  31 174 237  75  16 358   9  50  92 122 152 386 207 244\n",
       "[145] 229 350 355 391 223 373 309 140 126 349 344 319 258  15 271 388 195 201\n",
       "[163] 318  17 212 127 133  41 384 392 159 117  72  36 315 294 157 378 313 306\n",
       "[181] 272 106 185  88 281 228 238 368  80  30  93 234 220 240 369 164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73fdeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "?sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ead673",
   "metadata": {},
   "source": [
    "(Here we use a shortcut in the sample command; see `?sample` for details.)\n",
    "We then use the `subset` option in `lm()` to fit a linear regression using only the observations corresponding to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5f80aa",
   "metadata": {
    "name": "chunk2"
   },
   "outputs": [],
   "source": [
    "lm.fit <- lm(mpg ~ horsepower, data = Auto, subset = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd69a715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = mpg ~ horsepower, data = Auto, subset = train)\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)   horsepower  \n",
       "    41.2835      -0.1697  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae38b1",
   "metadata": {},
   "source": [
    "We now  use\n",
    " the `predict()` function to estimate the response for all $392$ observations,  and\n",
    " we  use\n",
    "  the `mean()` function to calculate the MSE of the $196$ observations in the validation set. Note that the `-train` index below selects  only the observations that are not in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bc8b67",
   "metadata": {
    "name": "chunk3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2660086465003"
      ],
      "text/latex": [
       "23.2660086465003"
      ],
      "text/markdown": [
       "23.2660086465003"
      ],
      "text/plain": [
       "[1] 23.26601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attach(Auto)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd124e",
   "metadata": {},
   "source": [
    "Therefore, the estimated test MSE for the linear regression fit is $23.27$. We can use the `poly()` function to estimate the test error for the quadratic and cubic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39555396",
   "metadata": {
    "name": "chunk4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.7164594933828"
      ],
      "text/latex": [
       "18.7164594933828"
      ],
      "text/markdown": [
       "18.7164594933828"
      ],
      "text/plain": [
       "[1] 18.71646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "18.7940067973945"
      ],
      "text/latex": [
       "18.7940067973945"
      ],
      "text/markdown": [
       "18.7940067973945"
      ],
      "text/plain": [
       "[1] 18.79401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, \n",
    "    subset = train)\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, \n",
    "    subset = train)\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0549e0",
   "metadata": {},
   "source": [
    "These error rates are $18.72$ and $18.79$, respectively.\n",
    "If we choose a different training set instead, then we will obtain somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259e0074",
   "metadata": {
    "name": "chunk5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "25.7265106448139"
      ],
      "text/latex": [
       "25.7265106448139"
      ],
      "text/markdown": [
       "25.7265106448139"
      ],
      "text/plain": [
       "[1] 25.72651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20.4303642741463"
      ],
      "text/latex": [
       "20.4303642741463"
      ],
      "text/markdown": [
       "20.4303642741463"
      ],
      "text/plain": [
       "[1] 20.43036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20.3853268638776"
      ],
      "text/latex": [
       "20.3853268638776"
      ],
      "text/markdown": [
       "20.3853268638776"
      ],
      "text/plain": [
       "[1] 20.38533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "train <- sample(392, 196)\n",
    "lm.fit <- lm(mpg ~ horsepower, subset = train)\n",
    "mean((mpg - predict(lm.fit, Auto))[-train]^2)\n",
    "lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data = Auto, \n",
    "    subset = train)\n",
    "mean((mpg - predict(lm.fit2, Auto))[-train]^2)\n",
    "lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data = Auto, \n",
    "    subset = train)\n",
    "mean((mpg - predict(lm.fit3, Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b1497c",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set,\n",
    "we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $25.73$, $20.43$, and $20.39$, respectively.\n",
    "\n",
    "These results are consistent with our previous findings: a model that predicts `mpg` using a quadratic function of `horsepower` performs better than a model that involves only a linear function of `horsepower`, and there is little evidence in favor of a model that uses a cubic function of `horsepower`.\n",
    "\n",
    "## Leave-One-Out Cross-Validation\n",
    "\n",
    "The LOOCV estimate can be automatically computed for any generalized linear model   using the `glm()` and `cv.glm()` functions.  In the lab for Chapter 4, we used the `glm()` function to perform logistic regression by passing in  the `family = \"binomial\"` argument.\n",
    " But if we use `glm()` to fit a model without passing in the `family` argument, then it  performs linear regression, just like the `lm()` function.\n",
    "So for instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99306afa",
   "metadata": {
    "name": "chunk6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c22e0e",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e6035c0",
   "metadata": {
    "name": "chunk7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit <- lm(mpg ~ horsepower, data = Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3f7a7",
   "metadata": {},
   "source": [
    " yield identical linear regression models. In this lab, we will  perform linear regression using\n",
    " the `glm()` function rather than the `lm()` function because the former can be used together with\n",
    "`cv.glm()`. The `cv.glm()` function is part of the `boot` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8584a3d3",
   "metadata": {
    "name": "chunk8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179292</li><li>24.2311440937562</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "glm.fit <- glm(mpg ~ horsepower, data = Auto)\n",
    "cv.err <- cv.glm(Auto, glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7052115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$call\n",
       "cv.glm(data = Auto, glmfit = glm.fit)\n",
       "\n",
       "$K\n",
       "[1] 392\n",
       "\n",
       "$delta\n",
       "[1] 24.23151 24.23114\n",
       "\n",
       "$seed\n",
       "  [1]       10403         288  1654269195 -1877109783  -961256264  1403523942\n",
       "  [7]   124639233   261424787  1836448066  1034917620   -13630729   468718317\n",
       " [13]  1694379396  1559298986  1935866133 -1450855505  2105396150  1802260960\n",
       " [19]  1077391651   539731521   122505520   230898510 -1940184647  1223031755\n",
       " [25] -1597886342 -1854140036 -1783225921  1484611221  1365746860  -346485118\n",
       " [31]  1206044253  1201793367   956757054   350214264 -1324711077 -1071776071\n",
       " [37] -1831283960  1862871478  1826141937   268853539   607122290  1403468228\n",
       " [43] -1913257593  -346768547  -463801004  1625143162  1387501253  -280700897\n",
       " [49]   422985638   732086576  -725197869  1128169969 -1024391392 -1032957506\n",
       " [55]  -353082935 -1139485317   445858634  1224049580  -796824913   247650405\n",
       " [61]   542595100  -404965774  -423589651 -1999189721  1430762830 -1439787608\n",
       " [67] -1821953621  1808288457 -1668269352 -1099348090    24992353  -140278797\n",
       " [73]  1709299298   269218004  1210153431  -238785587  -383705244  -472446134\n",
       " [79]   -15672651  -538858993  1771793174   -40319552 -1632234109 -1613456479\n",
       " [85]  -109108336  2056208494   -22837735  -195336533   835590810    86083164\n",
       " [91]   517854047  -397095627 -1681163060   985204258   613283965  1720828279\n",
       " [97]   929066654  -293216936   348261563  1602155097  1188944360  -526197738\n",
       "[103] -1056856175  -999184317 -1361965230 -1531694108  1775225383  1578975869\n",
       "[109]  -305972364   499275610  -297283163 -1400910401  -628019642  -995328816\n",
       "[115]  -416901389  -131985391   838014528   160971294   516863209 -1388986853\n",
       "[121] -1140425174   -14278324  1980074767  1968938565  -674453508  1981972050\n",
       "[127] -1121442867  -907997817   494782574  1629589576    57352779 -1057292375\n",
       "[133]  2043531000 -1557378522 -2033982655 -1166473005 -1243272062  1507691188\n",
       "[139]   519478839  -214579923   -15421884  -257117334   917217237  1604258159\n",
       "[145] -1793932170  1404112800   895408227 -1228178175 -1129918352  1726708750\n",
       "[151] -1514890119 -1503646709 -1385642694   530830396 -1346935937  1552658645\n",
       "[157]   -31128340 -1631936958  1895821725   665429015  1197209982    25108280\n",
       "[163]  1382701083 -1944495751  1482522568  1344742390  2075751985   887378019\n",
       "[169]  2132045874   507710852 -1239616569 -1239992675  1300848148 -2078006086\n",
       "[175]  1822724357  1779634911  -346210458    68638448  -651383277   408315825\n",
       "[181] -2048675232  1331662846 -1134018679 -1715119941 -1026157430  -262084756\n",
       "[187] -1837320977  -648290523  -685012516  -699648078 -1959870803  -939002265\n",
       "[193]  1368704398  1604498024  -270455189   878774281 -1496090984  1651241414\n",
       "[199]  -719838943  -170397261  1455721762   967288596  1974706071 -1131741299\n",
       "[205]  1944879780   693669002   967713525   849937743  1265996374   507097344\n",
       "[211]  -355466173  2106394593   467134288  1892604334   231167833   250371435\n",
       "[217]  1139934426  -641921636  -858574433  -474934283 -2013707636 -1380890782\n",
       "[223]   119355197   993660855 -2002084770 -1013984872  -379702021   925663385\n",
       "[229]   -31002328  -442860704 -1075363102   641540264  1223098572 -1416033796\n",
       "[235]  1656623026  -797919760  1826465220   503635800   479382394  -180521552\n",
       "[241]   335149500  -762107820 -1027404862 -1827060960  1940004796   -55285168\n",
       "[247]   820174306 -1241009816   780750156  1441990908   182952690   711513856\n",
       "[253] -1637546380  2029275144  1579137466 -1032808496  -740935188  -653815916\n",
       "[259]   804057810 -1415082400  1411310924     1021216  -350965118  1885104616\n",
       "[265]   987875308  -131369412  1998212722 -1838333072   848054564  1637511736\n",
       "[271] -1985453670   185338320  1063452092 -1501837164  -244441982  -655956544\n",
       "[277]  1724949308  2018636944   664617762   824380936  -454972148  1579726236\n",
       "[283] -1666261486  -245134464   802374420  1526755624   260631610 -1205064752\n",
       "[289]  -361627028   937556532  -494404974   -99312288 -1390302900  1614862304\n",
       "[295]   774509986  1360092584  -193173876 -1314447940 -1663111566 -1553441808\n",
       "[301]  1474524740 -1146038184 -2113923014  1375914096 -1694107588  1286052116\n",
       "[307]  -244301118 -1394274592 -1799518084  1647537872  -826656350   363032616\n",
       "[313]   887266060  1523945916 -1606634702 -1705936192  1284490292  -611903800\n",
       "[319]   -82717510  1223915152  1740148460 -1417786796   261071506  -232439520\n",
       "[325]  -735589940 -1901903136    53278914 -1123929048  -739412052  1446503100\n",
       "[331] -1800705038  1762987568 -1902032988 -1903022664   152627034   717533328\n",
       "[337]   246260604  1132269844 -1594365630   343599360 -1585484356   763185488\n",
       "[343] -1647048414  -696819128   134752268 -1533188516 -1147008558  1720888832\n",
       "[349] -1992442540 -1205072664  1506019578   603356880  1553058604   599599348\n",
       "[355]  -568221294   -26303136  1900303372  -891679520 -1327582622  -770317144\n",
       "[361] -2141666228  1110458236 -1984349902   163365488  1002681156 -1830044712\n",
       "[367]  -482759814  1341773872 -1905328196 -2080945580   830894146  1654662816\n",
       "[373]   550937276  -155556912  -506636958  1307590376  1514790092  1301985788\n",
       "[379] -2135581198  1363303552  2121865716  1892557448  1059986234  1182360912\n",
       "[385] -1907645332 -1564824172  1223534674 -1003414048  1916359884  -428286304\n",
       "[391]  -449023614 -1081851672  1379461868   -76178116    39708786 -1623293328\n",
       "[397]   506321444  2118223928 -1103890150  -418716464 -1680746180 -1496452204\n",
       "[403]   625145730  1623387072  1943565884  1450672528  1732028450  1481551112\n",
       "[409]   487458956   872206108  -748118894  2140900736  -935907308   548710184\n",
       "[415] -1376221638  1162922448 -1448468116   593599412 -1498189294 -1658751008\n",
       "[421]   462232012   124672224   557945890  1357773608   781625868  1816482620\n",
       "[427]  -142301198  -510500112  1926556228   -13969832  -233818310 -1136707600\n",
       "[433]   460294844  -416275180  1083468994  -781480864  1355603324  1851695056\n",
       "[439]   578619682  -798888280  1535516556  -172522308  1128772402  -958671296\n",
       "[445] -1018973004  1397935176 -1571451462  1620720144  -804320020  -120377004\n",
       "[451]   539237138  1130743200  -645778740  1151912544  1355687874  1031070504\n",
       "[457] -1306313446   142889871   589573337 -1228012690 -1810984196 -1041194899\n",
       "[463]  -926225385 -1469796896  1488304574 -1061851253  -338333683 -2027587526\n",
       "[469]  -665470856  1572082721  -864508205  -357575180   -92260734  -727936233\n",
       "[475] -1218739743 -1034735834  1959295524 -2018968363   970828927  2088100120\n",
       "[481]  1582403638 -1341110589 -1107547387   214011554  -657752944 -1164080071\n",
       "[487]  -795818773  -913533476   200285194   752745215    63615817 -1335801634\n",
       "[493] -1217612148  -805518755 -1818050457 -1804608112   621505966   918960219\n",
       "[499]   676442173  -402544982 -1789574328   224036721  -764759837  -670177308\n",
       "[505]   261209874  -893263129  1281983665   362571510  1179824404  1440671269\n",
       "[511]  -385713361  -963744536  2009648582 -1648018317  -719300907  1092938930\n",
       "[517]   163127424   830016617  -184674085   343641132   154989626  -583638289\n",
       "[523]   424254841   484102670 -1823956004   550505549  -397533257  -309821120\n",
       "[529] -1833768930   947035883  1101549165  1819580122  1254016664   600796417\n",
       "[535]  -119647565   507059668  1219230946   981013879   178359489 -1798344634\n",
       "[541]   519307140  1302534453   -26966241  -277288328 -1009389738   145067491\n",
       "[547]   844768165 -1768828350 -1545351120  -672619431 -1158866485    15817276\n",
       "[553]  -881306518   -50051425 -1092056279  1196083134   248280748   296336381\n",
       "[559]   891261767   207606832 -1985825458 -2102088325  1662966493 -1304487158\n",
       "[565]   873339432   806441617  1094718083  1123275652   840202674   725952263\n",
       "[571]  -597236399 -1409356586  -114177612  1521819077   401542415  1975999368\n",
       "[577]   -10714458 -1167764909  1721318325 -2086876910   742005472   969609033\n",
       "[583]  -890084997 -1277850548  -971870758  1665781711   -20106855  1492599214\n",
       "[589]  1206353596   231206701  1215581399  -910904032  -626793858   303180875\n",
       "[595]   704691789  1846420602 -1294941000 -2057982367   787944467 -1144544716\n",
       "[601]  -630963134  1707080791   636622753  -866277274   434270308   154340245\n",
       "[607]   835108031 -1921487784   511924342 -1737570173   907225285   803644898\n",
       "[613]  -625275824 -1045666439 -1073554773 -1362001380  -645341878   459588927\n",
       "[619] -1339341943   -24970338 -2003084724  -426558435 -1332570713  -956733232\n",
       "[625]   355793518  1450597184\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a4086",
   "metadata": {},
   "source": [
    "The `cv.glm()` function produces a list with several components.  The two numbers in the `delta` vector contain the cross-validation results. In this case the numbers are identical (up to two decimal places) and correspond to the LOOCV statistic given in ( 5.1). Below, we discuss a situation in which the two numbers differ. Our cross-validation estimate for the test error is approximately $24.23$.\n",
    "\n",
    "We can repeat this procedure for increasingly complex polynomial fits.\n",
    " To automate the process, we use the  `for()` function to initiate a  which iteratively fits polynomial regressions for polynomials of order $i=1$ to $i=10$, computes the associated cross-validation error, and stores it in the $i$th element of the vector `cv.error`.\n",
    " We begin by initializing the vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f353e50",
   "metadata": {
    "name": "chunk9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2315135179292</li><li>19.2482131244897</li><li>19.3349840640291</li><li>19.4244303104303</li><li>19.0332138547041</li><li>18.9786436582254</li><li>18.8330450653183</li><li>18.9611507120531</li><li>19.0686299814599</li><li>19.4909322993336</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.3349840640291\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\item 18.9786436582254\n",
       "\\item 18.8330450653183\n",
       "\\item 18.9611507120531\n",
       "\\item 19.0686299814599\n",
       "\\item 19.4909322993336\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.3349840640291\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "6. 18.9786436582254\n",
       "7. 18.8330450653183\n",
       "8. 18.9611507120531\n",
       "9. 19.0686299814599\n",
       "10. 19.4909322993336\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.23151 19.24821 19.33498 19.42443 19.03321 18.97864 18.83305 18.96115\n",
       " [9] 19.06863 19.49093"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.error <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "  cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67634a57",
   "metadata": {},
   "source": [
    "As in Figure 5.4, we see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-order polynomials.\n",
    "\n",
    "## $k$-Fold Cross-Validation\n",
    "\n",
    "The `cv.glm()` function can also be used to implement $k$-fold CV. Below we use $k=10$, a common choice for $k$, on the `Auto` data set.\n",
    "We once again set a random seed and initialize a vector in which we will store the CV errors corresponding to the polynomial fits of orders one to ten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12806f8a",
   "metadata": {
    "name": "chunk10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>24.2720671232254</li><li>19.2690928085129</li><li>19.3480535605547</li><li>19.2949648229745</li><li>19.0319790002896</li><li>18.89781210564</li><li>19.1206066690695</li><li>19.1466631054789</li><li>18.8701307442148</li><li>20.9552042280384</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2720671232254\n",
       "\\item 19.2690928085129\n",
       "\\item 19.3480535605547\n",
       "\\item 19.2949648229745\n",
       "\\item 19.0319790002896\n",
       "\\item 18.89781210564\n",
       "\\item 19.1206066690695\n",
       "\\item 19.1466631054789\n",
       "\\item 18.8701307442148\n",
       "\\item 20.9552042280384\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2720671232254\n",
       "2. 19.2690928085129\n",
       "3. 19.3480535605547\n",
       "4. 19.2949648229745\n",
       "5. 19.0319790002896\n",
       "6. 18.89781210564\n",
       "7. 19.1206066690695\n",
       "8. 19.1466631054789\n",
       "9. 18.8701307442148\n",
       "10. 20.9552042280384\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.27207 19.26909 19.34805 19.29496 19.03198 18.89781 19.12061 19.14666\n",
       " [9] 18.87013 20.95520"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "cv.error.10 <- rep(0, 10)\n",
    "for (i in 1:10) {\n",
    "  glm.fit <- glm(mpg ~ poly(horsepower, i), data = Auto)\n",
    "  cv.error.10[i] <- cv.glm(Auto, glm.fit, K = 10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6887a5",
   "metadata": {},
   "source": [
    "Notice that the computation time is shorter than that of LOOCV.\n",
    "(In principle, the computation time for LOOCV for a least squares linear model should be faster than for $k$-fold CV, due to the availability\n",
    "of the formula ( 5.2) for LOOCV; however, unfortunately the `cv.glm()` function does not make use of this formula.)\n",
    "We still see little evidence that using cubic or higher-order polynomial terms leads to lower test error than simply using a quadratic fit.\n",
    "\n",
    "We saw in Section 5.3.2 that the two numbers associated with `delta` are essentially the same when LOOCV is performed.\n",
    "When we instead perform $k$-fold CV, then the two numbers associated with `delta` differ slightly. The first is the standard $k$-fold CV estimate,\n",
    "as in ( 5.3). The second is a bias-corrected version. On this data set, the two estimates are very similar to each other.\n",
    "\n",
    "## The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbb6ad",
   "metadata": {},
   "source": [
    "We illustrate the use of the bootstrap in the simple example of Section 5.2, as well as on an example involving estimating the\n",
    "accuracy of the linear regression model on the `Auto` data set.\n",
    "\n",
    "### Estimating the Accuracy of a Statistic of Interest\n",
    "\n",
    "One of the great advantages of the bootstrap approach is that it can be\n",
    "applied in almost all situations. No complicated mathematical calculations\n",
    "are required. Performing a bootstrap analysis in `R` entails only two\n",
    "steps. First, we must create a function that computes the statistic of\n",
    "interest. Second, we use the `boot()` function, which is part of the `boot` library, to perform the bootstrap by repeatedly\n",
    "sampling observations from the data set with replacement.\n",
    "\n",
    "The `Portfolio` data set in the `ISLR2` package is simulated data of $100$ pairs of returns, generated in the fashion described in Section 5.2.\n",
    "To illustrate the use of the bootstrap on this data, we must first\n",
    "create a function, `alpha.fn()`, which takes as input the $(X,Y)$ data\n",
    "as well as a vector indicating which observations should be used to\n",
    "estimate $\\alpha$. The function then outputs the estimate for $\\alpha$\n",
    "based on the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "996fc134",
   "metadata": {
    "name": "chunk11"
   },
   "outputs": [],
   "source": [
    "alpha.fn <- function(data, index) {\n",
    "  X <- data$X[index]\n",
    "  Y <- data$Y[index]\n",
    "  (var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76724d5e",
   "metadata": {},
   "source": [
    "This function *returns*, or outputs, an  estimate for $\\alpha$ based on applying ( 5.7) to the observations indexed by the argument `index`.\n",
    "For instance, the following command tells `R` to estimate $\\alpha$ using\n",
    "all $100$ observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06100bce",
   "metadata": {
    "name": "chunk12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57583207459283"
      ],
      "text/latex": [
       "0.57583207459283"
      ],
      "text/markdown": [
       "0.57583207459283"
      ],
      "text/plain": [
       "[1] 0.5758321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn(Portfolio, 1:100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cda089",
   "metadata": {},
   "source": [
    "The next command  uses the `sample()` function to randomly select\n",
    "$100$ observations from the range $1$ to $100$, with replacement. This is equivalent\n",
    "to constructing a new bootstrap data set and recomputing $\\hat{\\alpha}$\n",
    "based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9166f4d",
   "metadata": {
    "name": "chunk13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.538532591946793"
      ],
      "text/latex": [
       "0.538532591946793"
      ],
      "text/markdown": [
       "0.538532591946793"
      ],
      "text/plain": [
       "[1] 0.5385326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(7)\n",
    "alpha.fn(Portfolio, sample(100, 100, replace = T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d913d4",
   "metadata": {},
   "source": [
    "We can implement a bootstrap analysis by performing this command many times, recording all of\n",
    "the corresponding estimates for $\\alpha$, and computing the resulting\n",
    "standard deviation.\n",
    "However, the `boot()` function automates this approach. Below we produce $R=1,000$ bootstrap estimates for $\\alpha$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4d57757",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "chunk14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "     original       bias    std. error\n",
       "t1* 0.5758321 0.0007959475  0.08969074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Portfolio, alpha.fn, R = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58823115",
   "metadata": {},
   "source": [
    "The final output shows that using the original data, $\\hat{\\alpha}=0.5758$,\n",
    "and that the bootstrap estimate for ${\\rm SE}(\\hat{\\alpha})$ is $0.0897$.\n",
    "\n",
    "### Estimating the Accuracy of a Linear Regression Model\n",
    "\n",
    "The bootstrap approach can be used  to assess the\n",
    "variability of the coefficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of\n",
    "the estimates for $\\beta_0$ and $\\beta_1$, the intercept and slope terms for the linear regression model\n",
    "that uses  `horsepower` to predict `mpg` in the `Auto` data set. We will compare the estimates obtained using the bootstrap to those obtained using the formulas\n",
    "for ${\\rm SE}(\\hat{\\beta}_0)$ and ${\\rm SE}(\\hat{\\beta}_1)$ described\n",
    "in Section 3.1.2.\n",
    "\n",
    "We first create a simple function, `boot.fn()`, which takes in the\n",
    "`Auto` data set as well as a set of indices for the observations, and\n",
    "returns the intercept and slope estimates for the linear regression model. We then apply this function\n",
    "to the full set of $392$ observations in order to compute the estimates of $\\beta_0$ and $\\beta_1$ on the entire data set using the usual linear regression coefficient estimate\n",
    "formulas from Chapter 3. Note that we do not need the `{` and `}` at the beginning and end of the function because it is only one line long."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2481a51",
   "metadata": {},
   "source": [
    "Boostrap here is used to determine more accuare standard error values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556ab840",
   "metadata": {
    "name": "chunk15"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>39.9358610211705</dd><dt>horsepower</dt><dd>-0.157844733353654</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index)\n",
    "  coef(lm(mpg ~ horsepower, data = data, subset = index))\n",
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c04cf",
   "metadata": {},
   "source": [
    " The `boot.fn()` function can also be used in order to create\n",
    " bootstrap estimates for the intercept and slope terms by randomly sampling from among the observations with replacement. Here we give two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f62400a",
   "metadata": {
    "name": "chunk16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>40.3404516830189</dd><dt>horsepower</dt><dd>-0.163486837689938</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.3404516830189\n",
       "\\item[horsepower] -0.163486837689938\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.3404516830189horsepower\n",
       ":   -0.163486837689938\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.3404517  -0.1634868 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>(Intercept)</dt><dd>40.1186906449022</dd><dt>horsepower</dt><dd>-0.157706320543503</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 40.1186906449022\n",
       "\\item[horsepower] -0.157706320543503\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   40.1186906449022horsepower\n",
       ":   -0.157706320543503\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 40.1186906  -0.1577063 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "boot.fn(Auto, sample(392, 392, replace = T))\n",
    "boot.fn(Auto, sample(392, 392, replace = T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3bb50",
   "metadata": {},
   "source": [
    "Next, we use the `boot()` function to compute the standard errors of 1,000 bootstrap estimates for the intercept and slope terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "becb7122",
   "metadata": {
    "name": "chunk17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original        bias    std. error\n",
       "t1* 39.9358610  0.0544513229 0.841289790\n",
       "t2* -0.1578447 -0.0006170901 0.007343073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b27a40",
   "metadata": {},
   "source": [
    "This indicates that the bootstrap estimate for ${\\rm SE}(\\hat{\\beta}_0)$ is $0.84$, and that the bootstrap estimate for ${\\rm SE}(\\hat{\\beta}_1)$ is $0.0073$.\n",
    "As discussed in Section 3.1.2, standard formulas can be used to compute the standard errors for the regression coefficients in a linear model. These can be obtained using the  `summary()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cec25af1",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "chunk18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610</td><td>0.717498656</td><td> 55.65984</td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447</td><td>0.006445501</td><td>-24.48914</td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610 & 0.717498656 &  55.65984 & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447 & 0.006445501 & -24.48914 &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 39.9358610 | 0.717498656 |  55.65984 | 1.220362e-187 |\n",
       "| horsepower | -0.1578447 | 0.006445501 | -24.48914 |  7.031989e-81 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg ~ horsepower, data = Auto))$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4d5a4",
   "metadata": {},
   "source": [
    "The standard error estimates for $\\hat{\\beta}_0$ and\n",
    "$\\hat{\\beta}_1$ obtained using the formulas from\n",
    "Section 3.1.2 are $0.717$ for the intercept and $0.0064$\n",
    "for the slope. Interestingly, these are somewhat different from the\n",
    "estimates obtained using the bootstrap.  Does this indicate a problem\n",
    "with the bootstrap? In fact, it suggests the opposite.  Recall that\n",
    "the standard formulas given in Equation 3.8 on page66 rely on certain assumptions. For example, they depend\n",
    "on the unknown parameter $\\sigma^2$, the noise variance. We then estimate $\\sigma^2$\n",
    "using the RSS. Now although the formulas for the standard errors do not rely on the linear model\n",
    "being correct, the estimate for $\\sigma^2$ does.\n",
    "We see in\n",
    "Figure 3.8 on page91 that there is a non-linear relationship in\n",
    "the data, and so the residuals from a linear fit will be inflated, and so will $\\hat{\\sigma}^2$.\n",
    "Secondly, the standard formulas assume (somewhat unrealistically) that the $x_i$ are fixed, and all the variability comes from the variation in the errors $\\epsilon_i$.\n",
    " The bootstrap approach does not rely on any of these assumptions, and so it is\n",
    "likely giving a more accurate estimate of the standard errors of\n",
    "$\\hat{\\beta}_0$ and $\\hat{\\beta}_1$ than is the `summary()`\n",
    "function.\n",
    "\n",
    "Below we compute the bootstrap standard error estimates and the standard\n",
    "linear regression estimates that result from fitting the quadratic model to the data. Since this model provides a good fit to the data (Figure 3.8), there is now a better correspondence between the bootstrap estimates and the standard estimates of ${\\rm SE}(\\hat{\\beta}_0)$, ${\\rm SE}(\\hat{\\beta}_1)$ and ${\\rm SE}(\\hat{\\beta}_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d5ca6e1",
   "metadata": {
    "lines_to_next_cell": 0,
    "name": "chunk19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "        original        bias     std. error\n",
       "t1* 56.900099702  3.511640e-02 2.0300222526\n",
       "t2* -0.466189630 -7.080834e-04 0.0324241984\n",
       "t3*  0.001230536  2.840324e-06 0.0001172164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>56.900099702</td><td>1.8004268063</td><td> 31.60367</td><td>1.740911e-109</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.466189630</td><td>0.0311246171</td><td>-14.97816</td><td> 2.289429e-40</td></tr>\n",
       "\t<tr><th scope=row>I(horsepower^2)</th><td> 0.001230536</td><td>0.0001220759</td><td> 10.08009</td><td> 2.196340e-21</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 56.900099702 & 1.8004268063 &  31.60367 & 1.740911e-109\\\\\n",
       "\thorsepower & -0.466189630 & 0.0311246171 & -14.97816 &  2.289429e-40\\\\\n",
       "\tI(horsepower\\textasciicircum{}2) &  0.001230536 & 0.0001220759 &  10.08009 &  2.196340e-21\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 56.900099702 | 1.8004268063 |  31.60367 | 1.740911e-109 |\n",
       "| horsepower | -0.466189630 | 0.0311246171 | -14.97816 |  2.289429e-40 |\n",
       "| I(horsepower^2) |  0.001230536 | 0.0001220759 |  10.08009 |  2.196340e-21 |\n",
       "\n"
      ],
      "text/plain": [
       "                Estimate     Std. Error   t value   Pr(>|t|)     \n",
       "(Intercept)     56.900099702 1.8004268063  31.60367 1.740911e-109\n",
       "horsepower      -0.466189630 0.0311246171 -14.97816  2.289429e-40\n",
       "I(horsepower^2)  0.001230536 0.0001220759  10.08009  2.196340e-21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn <- function(data, index)\n",
    "  coef(\n",
    "      lm(mpg ~ horsepower + I(horsepower^2), \n",
    "        data = data, subset = index)\n",
    "    )\n",
    "set.seed(1)\n",
    "boot(Auto, boot.fn, 1000)\n",
    "summary(\n",
    "    lm(mpg ~ horsepower + I(horsepower^2), data = Auto)\n",
    "  )$coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfca3e8",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "substitutions": {
   "ISLPmod": "`ISLP`",
   "Rlang": "`R`",
   "mpl": "`matplotlib`",
   "numpy": "`numpy`",
   "pandas": "`pandas`",
   "pylang": "`python`",
   "smlib": "`statsmodels`"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
